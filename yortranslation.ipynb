{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "yortranslation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fajemila/yorubanlptoen/blob/main/yortranslation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPkQXJnJQU6D",
        "outputId": "798b6d10-6f70-4a80-a99c-caad8aa533f2"
      },
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 30.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 22.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 26.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 24.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 27.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HunniL9qoZjm",
        "outputId": "22ace63d-2a2e-451f-dd23-0fa554d6f382"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpzMxahioZjt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Field, BucketIterator\n",
        "import string\n",
        "import spacy\n",
        "from torchtext import data\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ibSOTfqX85Qa",
        "outputId": "4c4dcab8-4b30-4af4-8710-9c9d560345a0"
      },
      "source": [
        "import torchtext\n",
        "torchtext.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.6.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0GA8u9OoZjw"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epFWpY6ooZjx"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUto2KrSoZjz"
      },
      "source": [
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "tokenize_yr = lambda x: str(x).translate(str.maketrans('', '', string.punctuation)).strip().split()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUZKEShloZj0"
      },
      "source": [
        "ID = Field()\n",
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True,\n",
        "            batch_first = True,\n",
        "            fix_length=50)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True,\n",
        "            batch_first = True,\n",
        "            fix_length=50)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ58b6OmoZj2"
      },
      "source": [
        "from torchtext import data\n",
        "tv_datafields = [('ID', None),(\"Yoruba\", SRC), (\"English\", TRG)]\n",
        "train_data = data.TabularDataset(path='drive/MyDrive/yorubatoEN/Train.csv',format=\"csv\",\n",
        "                                                skip_header=True, fields =tv_datafields)\n",
        "test_data = data.TabularDataset(path='drive/MyDrive/yorubatoEN/Test.csv', format=\"csv\",\n",
        "                                                skip_header=True, fields =[('ID', None),(\"Yoruba\", SRC)])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R79vCCdoZj3",
        "outputId": "d73ad9ba-ff35-4a16-9206-482e937be400"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 10054\n",
            "Number of testing examples: 6816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg4VStPfoZj4",
        "outputId": "1c8991eb-2339-44d2-b326-c0c67bffe949"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Yoruba': ['a', 'ṣètò', 'ìgbìmọ̀', 'tó', 'ń', 'ṣètò', 'ìrànwọ́', 'nígbà', 'àjálù', 'láti', 'wá', 'bí', 'àwọn', 'ará', 'wa', 'níbẹ̀', 'ṣe', 'máa', 'rí', 'àwọn', 'nǹkan', 'tí', 'wọ́n', 'máa', 'nílò', 'lọ́jọ́', 'iwájú', '.'], 'English': ['a', 'disaster', 'relief', 'committee', 'was', 'formed', 'to', 'organize', 'the', 'long', '-', 'term', 'relief', 'efforts', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SLTykrAoZj6"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(split_ratio=0.9,random_state = random.seed(SEED))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KVL8_jgoZj7"
      },
      "source": [
        "SRC.build_vocab(train_data, max_size =10000)\n",
        "TRG.build_vocab(train_data, max_size =10000)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "vdo2Q9mq6om1",
        "outputId": "96637082-8ad9-410b-8a45-1836528f1974"
      },
      "source": [
        "SRC.pad_token"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<pad>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "yVVyoUr-6om2",
        "outputId": "98adf91b-2352-41c5-ec76-c5cea7d32fe3"
      },
      "source": [
        "TRG.pad_token"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<pad>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MinI2NRToZj8",
        "outputId": "47acc1fa-da35-416c-b37f-998511c1e60f"
      },
      "source": [
        "print(f\"Unique tokens in source (yr) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (yr) vocabulary: 10004\n",
            "Unique tokens in target (en) vocabulary: 10004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ejcyLQ6om2"
      },
      "source": [
        "def save_vocab(vocab,path):\n",
        "    import pickle\n",
        "    output = open(path,'wb')\n",
        "    pickle.dump(vocab,output)\n",
        "    output.close"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8gB7RWi6om3"
      },
      "source": [
        "save_vocab(SRC.vocab,'srcvocab.pkl')\n",
        "save_vocab(TRG.vocab,'trgvocab.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn6mvZzXoZj9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-MBzbikoZj-"
      },
      "source": [
        "train_iter , valid_iter = data.BucketIterator.splits((train_data,valid_data), device=device, \n",
        "                                 batch_sizes=(1,1),\n",
        "                                 sort_key = lambda x: data.interleave_keys(len(x.Yoruba),len(x.English)),\n",
        "                                 sort_within_batch=True, repeat=False)\n",
        "test_iter = data.Iterator(test_data,batch_size=16,device=device,train=False,sort=False,sort_within_batch=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOOVBkvNoZj_"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 50):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2KW8tLuiCr"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, src len]\n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnEfPUaVQRNX"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7b_YKX3QRNe"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BomEbaNrQRNh"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 50):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, trg len]\n",
        "        #src_mask = [batch size, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mRnTjqFQRNp"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, trg len]\n",
        "        #src_mask = [batch size, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9fQBu_IoZkC"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv7WBloaoZkP"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 6\n",
        "DEC_LAYERS = 1\n",
        "ENC_HEADS = 4\n",
        "DEC_HEADS = 4\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIXwhyoJQRNt"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Gbgw4NpoZkd",
        "outputId": "a2b2c446-38c0-4b7f-d003-1a84f6531c56"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 11,672,084 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfe2CJYvQRNv"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RONfV4rfQRNw"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YYqEP4loZke"
      },
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eMOx0ChoZkf"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.Yoruba\n",
        "        trg = batch.English\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "        \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "        \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNaznJJ7oZkg"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.Yoruba\n",
        "            trg = batch.English\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "        \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj0rBWbJoZki"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "lu7mvejDoZkj",
        "outputId": "9b7de36c-ec12-4186-d5b8-96f527473073"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "from torch.nn import functional as F\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iter, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 6m 24s\n",
            "\tTrain Loss: 5.760 | Train PPL: 317.379\n",
            "\t Val. Loss: 5.036 |  Val. PPL: 153.795\n",
            "Epoch: 02 | Time: 6m 25s\n",
            "\tTrain Loss: 4.809 | Train PPL: 122.649\n",
            "\t Val. Loss: 4.747 |  Val. PPL: 115.231\n",
            "Epoch: 03 | Time: 6m 26s\n",
            "\tTrain Loss: 4.371 | Train PPL:  79.158\n",
            "\t Val. Loss: 4.654 |  Val. PPL: 105.054\n",
            "Epoch: 04 | Time: 6m 32s\n",
            "\tTrain Loss: 4.040 | Train PPL:  56.800\n",
            "\t Val. Loss: 4.579 |  Val. PPL:  97.444\n",
            "Epoch: 05 | Time: 6m 30s\n",
            "\tTrain Loss: 3.764 | Train PPL:  43.132\n",
            "\t Val. Loss: 4.601 |  Val. PPL:  99.543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-05bb84e19348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-3943f4fb246c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                     \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0mrelevant_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m             \u001b[0;31m# TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JsCkYuG39_r",
        "outputId": "d740ed29-9e89-490e-ad2d-dc1c914d7a66"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 4.579 | Test PPL:  97.444 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnHfkfepsUbp"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPe8qFBw1cj5"
      },
      "source": [
        "def display_attention(sentence, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "        \n",
        "    attention = attention.squeeze(0).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=15)\n",
        "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                       rotation=45)\n",
        "    ax.set_yticklabels(['']+translation)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE44RybY1dqb",
        "outputId": "dee84e86-c4de-4e8c-9bc6-772c8bc15c43"
      },
      "source": [
        "example_idx = 5\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['Yoruba']\n",
        "trg = vars(train_data.examples[example_idx])['English']\n",
        "\n",
        "print(f'Yoruba = {src}')\n",
        "print(f'English = {trg}')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yoruba = ['àwọn', 'afẹ̀hónúhàn', 'kóra', 'jọ', 'láti', 'fi', 'òpin', 'sí', 'ikọ̀', 'sars', 'ní', 'ọjọ́', '13', ',', 'oṣù', 'òwàrà', ',', 'ọdún', '2020', ',', 'ní', 'ikeja', ',', 'èkó', '.']\n",
            "English = ['protesters', 'gather', 'to', 'end', 'sars', 'on', 'october', '13', ',', '2020', ',', 'in', 'ikeja', ',', 'lagos', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnTsQZsg1g0h",
        "outputId": "691d9cae-66b9-4285-c868-8817d7a3b722"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted English = {translation}')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted English = ['the', 'president', 'of', 'the', 'president', 'muhammadu', 'buhari', 'has', 'been', 'of', 'the', 'super', 'eagles', ',', 'who', 'is', 'the', 'world', 'cup', 'in', 'the', 'world', 'cup', 'in', 'the', 'world', 'cup', 'in', 'the', 'world', 'cup', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "t-EGp-vn1jK9",
        "outputId": "4d699d25-ddcd-40a4-a78f-f43720b79294"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "display_attention(src, translation, attention)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-6933763527e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdisplay_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-70-29ba19def7ed>\u001b[0m in \u001b[0;36mdisplay_attention\u001b[0;34m(sentence, translation, attention)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bone'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mmatshow\u001b[0;34m(self, Z, **kwargs)\u001b[0m\n\u001b[1;32m   7789\u001b[0m               \u001b[0;34m'aspect'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'equal'\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# (already the imshow default)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7790\u001b[0m               **kwargs}\n\u001b[0;32m-> 7791\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7792\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7793\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (4, 33, 27) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0gGQPi64Obu"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    for datum in data:\n",
        "        \n",
        "        src = vars(datum)['Yoruba']\n",
        "        trg = vars(datum)['English']\n",
        "        \n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        \n",
        "        #cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        \n",
        "    return bleu_score(pred_trgs, trgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC7qufb34TID",
        "outputId": "33827527-3f79-41f4-a0e3-8c4231baa462"
      },
      "source": [
        "bleu_score = calculate_bleu(valid_data, SRC, TRG, model, device)\n",
        "\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score = 3.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BDQwA7F6fhs"
      },
      "source": [
        "trgs = []\n",
        "pred_trgs = []\n",
        "\n",
        "for datum in test_data:\n",
        "    \n",
        "    src = vars(datum)['Yoruba']\n",
        "    if len(src)>48:\n",
        "      src= src[:48]\n",
        "    pred_trg, _ = translate_sentence(src, SRC, TRG, model, device, 50)\n",
        "    \n",
        "    #cut off <eos> token\n",
        "    pred_trg = pred_trg[:-1]\n",
        "    \n",
        "    pred_trgs.append(pred_trg)    "
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "ENOyb3Pd70sT",
        "outputId": "f3b18a0f-9657-4a58-edb9-a5640c0575ef"
      },
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv('drive/MyDrive/yorubatoEN/Test.csv')\n",
        "test.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Yoruba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_AAAitMaH</td>\n",
              "      <td>Nínú ìpè kan lẹ́yìn ìgbà náà, wọ́n sọ fún aṣoj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_AAKKdQwr</td>\n",
              "      <td>Nítorí kò sí nǹkan tí ọkùnrin ò lè ṣe láì náán...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_ABgAyEOp</td>\n",
              "      <td>Bí i kó pariwo. Kí ó kígbe mọ́ ẹ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_ACFgfKQs</td>\n",
              "      <td>Tí ó ń lé e lọ sọ́nà etí odò Akókurà, tí ó bẹ̀...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_ACNPmlhf</td>\n",
              "      <td>Èṣúńiyì mọ̀ iṣẹ́ rẹ̀ dunjú. Màmá tirí bí ó ṣe ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            ID                                             Yoruba\n",
              "0  ID_AAAitMaH  Nínú ìpè kan lẹ́yìn ìgbà náà, wọ́n sọ fún aṣoj...\n",
              "1  ID_AAKKdQwr  Nítorí kò sí nǹkan tí ọkùnrin ò lè ṣe láì náán...\n",
              "2  ID_ABgAyEOp                  Bí i kó pariwo. Kí ó kígbe mọ́ ẹ?\n",
              "3  ID_ACFgfKQs  Tí ó ń lé e lọ sọ́nà etí odò Akókurà, tí ó bẹ̀...\n",
              "4  ID_ACNPmlhf  Èṣúńiyì mọ̀ iṣẹ́ rẹ̀ dunjú. Màmá tirí bí ó ṣe ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHBYIq_F8ng2"
      },
      "source": [
        "test['English'] = pred_trgs"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "Rd475ZOd8v9Q",
        "outputId": "0bc5eb37-fba8-4e8b-813d-ff0b07ad885d"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Yoruba</th>\n",
              "      <th>English</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_AAAitMaH</td>\n",
              "      <td>Nínú ìpè kan lẹ́yìn ìgbà náà, wọ́n sọ fún aṣoj...</td>\n",
              "      <td>[we, are, confident, that, jehovah, will, cont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_AAKKdQwr</td>\n",
              "      <td>Nítorí kò sí nǹkan tí ọkùnrin ò lè ṣe láì náán...</td>\n",
              "      <td>[i, do, n't, know, that, i, want, to, know, ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_ABgAyEOp</td>\n",
              "      <td>Bí i kó pariwo. Kí ó kígbe mọ́ ẹ?</td>\n",
              "      <td>[what, is, the, person, who, is, the, &lt;unk&gt;, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_ACFgfKQs</td>\n",
              "      <td>Tí ó ń lé e lọ sọ́nà etí odò Akókurà, tí ó bẹ̀...</td>\n",
              "      <td>[“, we, are, not, to, be, able, to, see, you, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_ACNPmlhf</td>\n",
              "      <td>Èṣúńiyì mọ̀ iṣẹ́ rẹ̀ dunjú. Màmá tirí bí ó ṣe ...</td>\n",
              "      <td>[it, is, the, &lt;unk&gt;, that, one, 's, own, child...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            ID  ...                                            English\n",
              "0  ID_AAAitMaH  ...  [we, are, confident, that, jehovah, will, cont...\n",
              "1  ID_AAKKdQwr  ...  [i, do, n't, know, that, i, want, to, know, ho...\n",
              "2  ID_ABgAyEOp  ...  [what, is, the, person, who, is, the, <unk>, o...\n",
              "3  ID_ACFgfKQs  ...  [“, we, are, not, to, be, able, to, see, you, ...\n",
              "4  ID_ACNPmlhf  ...  [it, is, the, <unk>, that, one, 's, own, child...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwBmNSbb8vuu"
      },
      "source": [
        "test['English'] = [' '.join(map(str, l)) for l in test['English']]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "Rpi9-UTh-Wdw",
        "outputId": "285002d6-e8e7-4302-9962-77cb99274da4"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Yoruba</th>\n",
              "      <th>English</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_AAAitMaH</td>\n",
              "      <td>Nínú ìpè kan lẹ́yìn ìgbà náà, wọ́n sọ fún aṣoj...</td>\n",
              "      <td>we are confident that jehovah will continue to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_AAKKdQwr</td>\n",
              "      <td>Nítorí kò sí nǹkan tí ọkùnrin ò lè ṣe láì náán...</td>\n",
              "      <td>i do n't know that i want to know how to prote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_ABgAyEOp</td>\n",
              "      <td>Bí i kó pariwo. Kí ó kígbe mọ́ ẹ?</td>\n",
              "      <td>what is the person who is the &lt;unk&gt; of the &lt;un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_ACFgfKQs</td>\n",
              "      <td>Tí ó ń lé e lọ sọ́nà etí odò Akókurà, tí ó bẹ̀...</td>\n",
              "      <td>“ we are not to be able to see you , ” is the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_ACNPmlhf</td>\n",
              "      <td>Èṣúńiyì mọ̀ iṣẹ́ rẹ̀ dunjú. Màmá tirí bí ó ṣe ...</td>\n",
              "      <td>it is the &lt;unk&gt; that one 's own child .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            ID  ...                                            English\n",
              "0  ID_AAAitMaH  ...  we are confident that jehovah will continue to...\n",
              "1  ID_AAKKdQwr  ...  i do n't know that i want to know how to prote...\n",
              "2  ID_ABgAyEOp  ...  what is the person who is the <unk> of the <un...\n",
              "3  ID_ACFgfKQs  ...  “ we are not to be able to see you , ” is the ...\n",
              "4  ID_ACNPmlhf  ...            it is the <unk> that one 's own child .\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkwaYgH58zNX"
      },
      "source": [
        "test[['ID','English']].to_csv('yorsolution.csv',index=False)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxPeAKT_-ypj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}